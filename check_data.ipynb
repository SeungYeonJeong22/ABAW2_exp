{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "annotation_dir      = \"../data/Affwild2/annotations/\"\n",
    "crop_ali_img1_dir   = \"../data/Affwild2/cropped_aligned_images1/cropped_aligned/\"\n",
    "crop_img1_dir       = \"../data/Affwild2/cropped_images1/batch1/\"\n",
    "crop_img2_dir       = \"../data/Affwild2/cropped_images2/batch2/\"\n",
    "train_vid_dir       = \"../data/Affwild2/train_video/batch1/\"\n",
    "valid_vid_dir       = \"../data/Affwild2/valid_video/batch2/\"\n",
    "\n",
    "data_dir = [\n",
    "    annotation_dir,\n",
    "    crop_ali_img1_dir,\n",
    "    crop_img1_dir,\n",
    "    crop_img2_dir,\n",
    "    train_vid_dir,\n",
    "    valid_vid_dir\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Affwild2/cropped_aligned_images1/cropped_aligned/  :  564\n",
      "../data/Affwild2/cropped_images1/batch1/  :  355\n",
      "../data/Affwild2/cropped_images2/batch2/  :  209\n"
     ]
    }
   ],
   "source": [
    "# data중에 untitled라는 무의미한 폴더가 있는 것이 있었음\n",
    "\n",
    "# 130-25-1280x720_left\n",
    "# 135-24-1920x1080_right\n",
    "for ddir in data_dir:\n",
    "    for dir, subdir, file in os.walk(ddir):\n",
    "        if dir.__contains__(annotation_dir): continue\n",
    "        if len(subdir) == 0: continue\n",
    "        \n",
    "        print(dir, \" : \", len(subdir))\n",
    "        \n",
    "        \n",
    "        # if \"untitled folder\" in subdir[0] and len(subdir) == 1:\n",
    "        #     for f in os.listdir(os.path.join(dir,subdir[0])):\n",
    "        #         try:os.system(f\"mv -f {os.path.join(dir, subdir[0], f)} {os.path.join(dir)}\")\n",
    "        #         except:print(f)\n",
    "        #     os.system(f\"rm -rf {os.path.join(dir, subdir[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_train len :  475\n",
      "video_valid len :  73\n",
      "video_test len :  50\n",
      "total data len: 598\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../data/Affwild2/train_video/batch1\"\n",
    "valid_path = \"../data/Affwild2/valid_video/batch2\"\n",
    "test_path = \"../data/Affwild2/test_video/new_vids\"\n",
    "\n",
    "train_len = len(os.listdir(train_path))\n",
    "valid_len = len(os.listdir(valid_path))\n",
    "test_len = len(os.listdir(test_path))\n",
    "\n",
    "print(\"video_train len : \", train_len)\n",
    "print(\"video_valid len : \", valid_len)\n",
    "print(\"video_test len : \",  test_len)\n",
    "\n",
    "print(f\"total data len: {train_len + valid_len + test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annot_train_path len :  356\n",
      "annot_valid_path len :  76\n",
      "total annotation data len: 432\n"
     ]
    }
   ],
   "source": [
    "annot_train_path = \"../data/Affwild2/annotations/VA_Set/Train_Set\"\n",
    "annot_valid_path = \"../data/Affwild2/annotations/VA_Set/Validation_Set\"\n",
    "# annot_train_path = \"../data/Affwild2/annotations/AU_Detection_Challenge/Train_Set\"\n",
    "# annot_valid_path = \"../data/Affwild2/annotations/AU_Detection_Challenge/Validation_Set\"\n",
    "# annot_train_path = \"../data/Affwild2/annotations/EXPR_Classification_Challenge/Train_Set\"\n",
    "# annot_valid_path = \"../data/Affwild2/annotations/EXPR_Classification_Challenge/Validation_Set\"\n",
    "\n",
    "annot_train_len = len(os.listdir(annot_train_path))\n",
    "annot_valid_len = len(os.listdir(annot_valid_path))\n",
    "\n",
    "print(\"annot_train_path len : \", annot_train_len)\n",
    "print(\"annot_valid_path len : \", annot_valid_len)\n",
    "\n",
    "print(f\"total annotation data len: {annot_train_len + annot_valid_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
